---
sidebar_position: 5
title: Playground Examples
description: Interactive examples demonstrating logpare compression features
---

import { CompressionDemo } from '@site/src/components/CompressionDemo';

# Playground Examples

Try these interactive examples to see how logpare compresses different types of logs.

## Basic Compression

This simple example demonstrates how logpare identifies patterns in repetitive logs.

<CompressionDemo
  dataset="basic"
  title="Basic Log Patterns"
  description="Common application logs with errors, info messages, and warnings"
  allowFormatToggle={true}
/>

**What's happening here?**
- Similar ERROR messages are grouped into a single template
- Variable parts (IP addresses, timestamps) are replaced with `<*>`
- Each template shows how many times it occurred

---

## Real-World Examples

### Hadoop HDFS Logs

Distributed file system logs showing block operations, replication, and data transfers.

<CompressionDemo
  dataset="hdfs"
  title="HDFS Distributed System Logs"
  description="Real Hadoop logs with complex block IDs and network operations"
  format="detailed"
/>

**Key Features:**
- Block IDs automatically masked as variables
- IP addresses and ports extracted
- Similar operations grouped despite different block numbers

### Apache Spark Logs

Big data processing framework logs with service initialization and job execution.

<CompressionDemo
  dataset="spark"
  title="Spark Application Logs"
  description="Spark startup sequence and job execution patterns"
  format="summary"
/>

**Notice:**
- Service names preserved in templates
- Memory sizes and ports treated as variables
- Job IDs and file paths automatically masked

### Error Analysis

Focused on error patterns for incident response and debugging.

<CompressionDemo
  dataset="errors"
  title="Error Pattern Detection"
  description="Connection failures, auth errors, and API issues"
  format="detailed"
/>

**Extracted Metadata:**
- **URLs**: Automatically extracted from API errors
- **Status codes**: HTTP response codes (500, 503, etc.)
- **Correlation IDs**: Request/trace IDs for tracking
- **Severity**: Auto-detected error/warning/info levels

---

## Understanding the Output Formats

### Summary Format

Compact view showing:
- Template patterns with occurrence counts
- Overall compression statistics
- Sorted by frequency (most common first)

**Best for:**
- Quick overview of log patterns
- Identifying most frequent events
- Sharing compressed results

### Detailed Format

Complete view including:
- Sample variable values from actual logs
- Extracted metadata (URLs, status codes, IDs)
- Severity detection (error/warning/info)
- First and last line numbers

**Best for:**
- Debugging specific issues
- Understanding variable ranges
- Analyzing error patterns

### JSON Format

Machine-readable output with:
- Complete template metadata
- All extracted values
- Compression statistics
- Version field for compatibility

**Best for:**
- Programmatic analysis
- Integration with other tools
- Long-term storage

---

## Try It Yourself

Visit the [full playground](/playground) to:
- Upload your own log files
- Adjust compression parameters
- Experiment with different settings
- Download compressed results

---

## Next Steps

- **[Installation](/docs/intro)** - Add logpare to your project
- **[API Reference](/docs/api/compress)** - Complete API documentation
- **[CLI Usage](/docs/cli)** - Batch process log files
- **[Custom Preprocessing](/docs/guides/custom-preprocessing)** - Handle domain-specific formats
